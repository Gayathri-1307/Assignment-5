{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086129fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Score  0\n",
      "Soft Voting Score  0\n"
     ]
    }
   ],
   "source": [
    "#empty list\n",
    "#hard voitng score\n",
    "#soft voting score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "df.head()\n",
    "df.columns\n",
    "label_encoder= LabelEncoder()\n",
    "df['ChestPainType']=label_encoder.fit_transform(df['ChestPainType'])\n",
    "df['HeartDisease']=label_encoder.fit_transform(df['HeartDisease'])\n",
    "X=df.drop(['Name','Age','Gender','HeartDisease','RestingECG','ExerciseAngina','ST_Slope'],axis=1)\n",
    "Y=df['HeartDisease']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.20,random_state =42)\n",
    "estimator=[]\n",
    "estimator.append(('LR',LogisticRegression(solver='lbfgs',multi_class ='multinomial',max_iter= 200)))\n",
    "estimator.append(('SVC',SVC(gamma ='auto', probability = True)))\n",
    "estimator.append(('DTC', DecisionTreeClassifier()))\n",
    "vot_hard = VotingClassifier(estimators = estimator, voting ='hard')\n",
    "vot_hard.fit(X_train, y_train)\n",
    "y_pred = vot_hard.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Hard Voting Score % d\" % score)\n",
    "vot_soft= VotingClassifier(estimators=estimator,voting = 'soft')\n",
    "vot_soft.fit(X_train, y_train)\n",
    "y_pred = vot_soft.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Soft Voting Score % d\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf8313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87049007 0.12950993]\n",
      " [0.29422826 0.70577174]\n",
      " [0.28518494 0.71481506]\n",
      " [0.85624435 0.14375565]\n",
      " [0.21360279 0.78639721]\n",
      " [0.26721864 0.73278136]\n",
      " [0.02580282 0.97419718]\n",
      " [0.91827011 0.08172989]\n",
      " [0.79369061 0.20630939]\n",
      " [0.89973462 0.10026538]\n",
      " [0.80655321 0.19344679]\n",
      " [0.47560282 0.52439718]\n",
      " [0.3515572  0.6484428 ]\n",
      " [0.80388218 0.19611782]\n",
      " [0.20010163 0.79989837]\n",
      " [0.90874839 0.09125161]\n",
      " [0.90702696 0.09297304]\n",
      " [0.33418386 0.66581614]\n",
      " [0.8744594  0.1255406 ]\n",
      " [0.88637324 0.11362676]\n",
      " [0.79617271 0.20382729]\n",
      " [0.42256714 0.57743286]\n",
      " [0.13640279 0.86359721]\n",
      " [0.00580029 0.99419971]\n",
      " [0.91547249 0.08452751]\n",
      " [0.07181506 0.92818494]\n",
      " [0.83424386 0.16575614]\n",
      " [0.06201144 0.93798856]\n",
      " [0.03576726 0.96423274]\n",
      " [0.45009383 0.54990617]\n",
      " [0.22280165 0.77719835]\n",
      " [0.83733754 0.16266246]\n",
      " [0.22271079 0.77728921]\n",
      " [0.90022202 0.09977798]\n",
      " [0.0851217  0.9148783 ]\n",
      " [0.82532    0.17468   ]\n",
      " [0.90320009 0.09679991]\n",
      " [0.0247885  0.9752115 ]\n",
      " [0.23301357 0.76698643]\n",
      " [0.19404027 0.80595973]\n",
      " [0.08576005 0.91423995]\n",
      " [0.89295697 0.10704303]\n",
      " [0.43566841 0.56433159]\n",
      " [0.92161945 0.07838055]\n",
      " [0.40059419 0.59940581]\n",
      " [0.14714557 0.85285443]\n",
      " [0.86999651 0.13000349]\n",
      " [0.88052976 0.11947024]\n",
      " [0.82733865 0.17266135]\n",
      " [0.91595288 0.08404712]\n",
      " [0.91880264 0.08119736]\n",
      " [0.071411   0.928589  ]\n",
      " [0.01826213 0.98173787]\n",
      " [0.45922562 0.54077438]\n",
      " [0.08984075 0.91015925]\n",
      " [0.32818588 0.67181412]\n",
      " [0.62813341 0.37186659]\n",
      " [0.9754714  0.0245286 ]\n",
      " [0.81420073 0.18579927]\n",
      " [0.89700977 0.10299023]\n",
      " [0.88271024 0.11728976]\n",
      " [0.5355437  0.4644563 ]\n",
      " [0.78863577 0.21136423]\n",
      " [0.73662973 0.26337027]\n",
      " [0.27311869 0.72688131]\n",
      " [0.73300952 0.26699048]\n",
      " [0.80106832 0.19893168]\n",
      " [0.87929607 0.12070393]\n",
      " [0.82980927 0.17019073]\n",
      " [0.27331312 0.72668688]\n",
      " [0.83339898 0.16660102]\n",
      " [0.15879595 0.84120405]\n",
      " [0.99114111 0.00885889]\n",
      " [0.74161182 0.25838818]\n",
      " [0.0696     0.9304    ]\n",
      " [0.20427033 0.79572967]\n",
      " [0.85486544 0.14513456]\n",
      " [0.01619882 0.98380118]\n",
      " [0.17970966 0.82029034]\n",
      " [0.26004208 0.73995792]\n",
      " [0.24233465 0.75766535]]\n"
     ]
    }
   ],
   "source": [
    "#Weighted averaging\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "df.head()\n",
    "df.columns\n",
    "label_encoder= LabelEncoder()\n",
    "df['ChestPainType']=label_encoder.fit_transform(df['ChestPainType'])\n",
    "df['HeartDisease']=label_encoder.fit_transform(df['HeartDisease'])\n",
    "x=df.drop(['Name','Age','Gender','HeartDisease','RestingECG','ExerciseAngina','ST_Slope'],axis=1)\n",
    "y=df['HeartDisease']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)\n",
    "model1=DecisionTreeClassifier()\n",
    "model2=KNeighborsClassifier()\n",
    "model3=LogisticRegression()\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "pred1=model1.predict_proba(x_test)\n",
    "pred2=model2.predict_proba(x_test)\n",
    "pred3=model3.predict_proba(x_test)\n",
    "finalpred=(pred1*0.3+pred2*0.3+pred3*0.4)\n",
    "print(finalpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0f6ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of KNeighbors Classifier is: 71.60493827160494\n",
      "Accuracy of Naive Bayes Classifier: 85.18518518518519\n"
     ]
    }
   ],
   "source": [
    "#Stacking\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder= LabelEncoder()\n",
    "\n",
    "df = pd.read_csv(\"heart_edited.csv\")\n",
    "df.head()\n",
    "\n",
    "X = df.drop('HeartDisease',axis=1)\n",
    "y = df['HeartDisease']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "sc = StandardScaler()  # StandardScaler initialization\n",
    "var_transform = ['RestingBP','Cholesterol','FastingBS']\n",
    "\n",
    "X_train[var_transform] = sc.fit_transform(X_train[var_transform])  # Standardizing training data\n",
    "X_test[var_transform] = sc.transform(X_test[var_transform])\n",
    "\n",
    "KNC = KNeighborsClassifier()  # KNeighborsClassifier initialization\n",
    "NB = GaussianNB()  # GaussianNB initialization\n",
    "\n",
    "model_kNeighborsClassifier = KNC.fit(X_train, y_train)\n",
    "pred_knc = model_kNeighborsClassifier.predict(X_test)\n",
    "acc_knc = accuracy_score(y_test, pred_knc)  # Evaluating accuracy score\n",
    "print('Accuracy score of KNeighbors Classifier is:', acc_knc * 100)\n",
    "\n",
    "model_NaiveBayes = NB.fit(X_train, y_train)\n",
    "pred_nb = model_NaiveBayes.predict(X_test)\n",
    "acc_nb = accuracy_score(y_test, pred_nb)\n",
    "print('Accuracy of Naive Bayes Classifier:', acc_nb * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0607f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of Stacked model: 79.01234567901234\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "lr = LogisticRegression()\n",
    "clf_stack = StackingClassifier(classifiers =[KNC, NB],\n",
    "                               meta_classifier = lr, \n",
    "                               use_probas = True, \n",
    "                               use_features_in_secondary = True)\n",
    "model_stack = clf_stack.fit(X_train, y_train)\n",
    "pred_stack = model_stack.predict(X_test)\n",
    "acc_stack = accuracy_score(y_test, pred_stack)\n",
    "print('accuracy score of Stacked model:', acc_stack * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f72d41d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(n_estimators=2, random_state=22)\n",
      "BaggingClassifier(n_estimators=4, random_state=22)\n",
      "BaggingClassifier(n_estimators=6, random_state=22)\n",
      "BaggingClassifier(n_estimators=8, random_state=22)\n",
      "BaggingClassifier(random_state=22)\n",
      "BaggingClassifier(n_estimators=12, random_state=22)\n",
      "BaggingClassifier(n_estimators=14, random_state=22)\n",
      "BaggingClassifier(n_estimators=16, random_state=22)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OutStream' object has no attribute 'buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#Two  lines to make our compiler able to draw:\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer\u001b[49m)\n\u001b[0;32m     46\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OutStream' object has no attribute 'buffer'"
     ]
    }
   ],
   "source": [
    "#Bagging\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data=pd.read_csv(\"heart_edited.csv\")\n",
    "data.head()\n",
    "data.columns\n",
    "label_encoder=LabelEncoder()\n",
    "X=data.drop(['HeartDisease'],axis=1)\n",
    "y=data['HeartDisease']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n",
    "estimator_range = [2,4,6,8,10,12,14,16]\n",
    "models = []\n",
    "scores = []\n",
    "for n_estimators in estimator_range:\n",
    "    \n",
    "    # Create bagging classifier\n",
    "    clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22)\n",
    "    print(clf)\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Append the model and score to their respective list\n",
    "    models.append(clf)\n",
    "    scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(estimator_range, scores)\n",
    "\n",
    "# Adjust labels and font (to make visable)\n",
    "plt.xlabel(\"n_estimators\", fontsize = 18)\n",
    "plt.ylabel(\"score\", fontsize = 18)\n",
    "plt.tick_params(labelsize = 16)\n",
    "\n",
    "# Visualize plot\n",
    "plt.show()\n",
    "\n",
    "#Two  lines to make our compiler able to draw:\n",
    "plt.savefig(sys.stdout.buffer)\n",
    "sys.stdout.flush()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bdcb52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Averaging Accuracy: 0.8271604938271605\n",
      "Stacking Accuracy: 0.8395061728395061\n",
      "Blending Accuracy: 0.8271604938271605\n",
      "Boosting Accuracy: 0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "#Belnding\n",
    "#Boosting\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"heart_edited.csv\")\n",
    "\n",
    "# Handle missing values by filling with column means\n",
    "numerical_cols = data.select_dtypes(include=['number']).columns\n",
    "data[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].mean())\n",
    "\n",
    "# Assuming 'Potability' is the target variable, and other columns are features\n",
    "X = data.drop(columns=['HeartDisease'])\n",
    "y = data['HeartDisease']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Base models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Fit the base models\n",
    "rf_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "gb_preds = gb_model.predict(X_test)\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "\n",
    "# Weighted Averaging\n",
    "weighted_avg_preds = (0.4 * rf_preds + 0.4 * gb_preds + 0.2 * lr_preds)\n",
    "\n",
    "# Stacking\n",
    "stacked_model = StackingClassifier(estimators=[('rf', rf_model), ('gb', gb_model), ('lr', lr_model)])\n",
    "stacked_model.fit(X_train, y_train)\n",
    "stacked_preds = stacked_model.predict(X_test)\n",
    "\n",
    "# Blending\n",
    "blend_preds = (rf_preds + gb_preds) / 2\n",
    "\n",
    "# Boosting (using GradientBoostingClassifier as an example)\n",
    "boosted_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "boosted_model.fit(X_train, y_train)\n",
    "boosted_preds = boosted_model.predict(X_test)\n",
    "\n",
    "import numpy as np  # Import NumPy for array operations\n",
    "\n",
    "# Convert weighted_avg_preds to binary predictions\n",
    "threshold = 0.5  # You can adjust the threshold as needed\n",
    "binary_weighted_avg_preds = np.where(weighted_avg_preds >= threshold, 1, 0)\n",
    "\n",
    "# Convert blend_preds to binary predictions\n",
    "binary_blend_preds = np.where(blend_preds >= threshold, 1, 0)\n",
    "\n",
    "# Evaluate the models with binary predictions\n",
    "print(\"Weighted Averaging Accuracy:\", accuracy_score(y_test, binary_weighted_avg_preds))\n",
    "print(\"Stacking Accuracy:\", accuracy_score(y_test, stacked_preds))\n",
    "print(\"Blending Accuracy:\", accuracy_score(y_test, binary_blend_preds))\n",
    "print(\"Boosting Accuracy:\", accuracy_score(y_test, boosted_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1754638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e7f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77406f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
